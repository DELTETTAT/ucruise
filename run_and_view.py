import subprocess
import threading
import time
import webbrowser
import sys
from assignment import run_assignment, analyze_assignment_quality

SOURCE_ID = "UC_logisticllp"  # <-- Replace with your real source_id
PARAMETER = 1  # Example numerical parameter
STRING_PARAM = "Evening%20shift" # Example string parameter

def start_fastapi():
    subprocess.run(["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "5000", "--reload"])

def launch_browser():
    time.sleep(5)  # Wait longer for server to start
    try:
        webbrowser.open("http://localhost:5000/visualize")
        print("ğŸŒ Browser opened at: http://localhost:5000/visualize")
    except Exception as e:
        print(f"âš ï¸  Could not auto-open browser: {e}")
        print("   Please manually visit: http://localhost:5000/visualize")

def display_detailed_analytics(result):
    """Display comprehensive analytics in terminal with enhanced formatting"""
    print("\n" + "ğŸ¯" + "="*78 + "ğŸ¯")
    print("ğŸ“Š ROUTEFLOW - INTELLIGENT ASSIGNMENT ANALYTICS DASHBOARD")
    print("ğŸ¯" + "="*78 + "ğŸ¯")

    if result["status"] != "true":
        print("âŒ Assignment failed - no analytics available")
        return

    # Basic metrics
    routes = result["data"]
    unassigned_users = result.get("unassignedUsers", [])
    unassigned_drivers = result.get("unassignedDrivers", [])

    total_assigned = sum(len(route["assigned_users"]) for route in routes)
    total_users = total_assigned + len(unassigned_users)

    # Handle no users case
    if total_users == 0:
        print("\nğŸ“ˆ SYSTEM OVERVIEW")
        print("â”€" * 50)
        print(f"   ğŸš— Active Routes Created: {len(routes)}")
        print(f"   ğŸ‘¥ Users Successfully Assigned: 0")
        print(f"   âš ï¸  Users Unassigned: 0")
        print(f"   ğŸš™ Drivers Deployed: 0")
        print(f"   ğŸ’¤ Drivers Available: {len(unassigned_drivers)}")
        print(f"   ğŸ† Total Fleet Capacity: 0 passengers")
        print(f"\nâ„¹ï¸  No users found for assignment")
        print(f"   ğŸ“Š System ready for user assignment when users are available")
        return

    total_capacity = sum(route["vehicle_type"] for route in routes)

    # Enhanced Overview Section
    print(f"\nğŸ“ˆ SYSTEM OVERVIEW")
    print("â”€" * 50)
    print(f"   ğŸš— Active Routes Created: {len(routes)}")
    print(f"   ğŸ‘¥ Users Successfully Assigned: {total_assigned}")
    print(f"   âš ï¸  Users Unassigned: {len(unassigned_users)}")
    print(f"   ğŸš™ Drivers Deployed: {len(routes)}")
    print(f"   ğŸ’¤ Drivers Available: {len(unassigned_drivers)}")
    print(f"   ğŸ† Total Fleet Capacity: {total_capacity} passengers")
    print(f"   ğŸ“Š Overall Capacity Utilization: {(total_assigned/total_capacity*100):.1f}%")

    # Enhanced Route Performance Analysis
    utilizations = []
    high_efficiency = 0
    medium_efficiency = 0
    low_efficiency = 0
    total_route_distance = 0

    # Driver priority analysis
    assigned_drivers = {route["driver_id"]: route for route in routes}
    unassigned_driver_ids = {d["driver_id"] for d in unassigned_drivers}

    print(f"\nğŸš— DETAILED ROUTE PERFORMANCE ANALYSIS")
    print("â”€" * 50)

    for i, route in enumerate(routes):
        assigned = len(route["assigned_users"])
        capacity = route["vehicle_type"]
        utilization = assigned / capacity
        utilizations.append(utilization)

        # Calculate route distance metrics
        route_distances = []
        for user in route["assigned_users"]:
            dist = haversine_distance(float(route["latitude"]), float(route["longitude"]),
                                    float(user["lat"]), float(user["lng"]))
            route_distances.append(dist)

        avg_route_distance = sum(route_distances) / len(route_distances) if route_distances else 0
        max_route_distance = max(route_distances) if route_distances else 0
        total_route_distance += avg_route_distance

        # Efficiency categorization
        if utilization >= 0.8:
            efficiency_icon = "ğŸŸ¢"
            efficiency_label = "EXCELLENT"
            high_efficiency += 1
        elif utilization >= 0.6:
            efficiency_icon = "ğŸŸ¡"
            efficiency_label = "GOOD"
            medium_efficiency += 1
        elif utilization >= 0.4:
            efficiency_icon = "ğŸŸ "
            efficiency_label = "FAIR"
            medium_efficiency += 1
        else:
            efficiency_icon = "ğŸ”´"
            efficiency_label = "NEEDS OPTIMIZATION"
            low_efficiency += 1

        # Get driver source info from the assignment result data structure
        # Since we're looking at routes that were created, we need to check the original data
        # The route driver_id should match drivers from the available pool

        # First check if this driver exists in unassigned_drivers list (these are the drivers that WEREN'T used)
        driver_found_in_unused = False
        for unused_driver in unassigned_drivers:
            if str(unused_driver.get("driver_id", "")) == str(route["driver_id"]):
                driver_found_in_unused = True
                break

        # If driver is NOT in the unused drivers list, it means this driver WAS used
        # We need to determine source from the original data structure
        # Since we have more driversUnassigned (45) than driversAssigned (0),
        # and our priority system shows Priority 1 and 2 drivers, they're from driversUnassigned

        if not driver_found_in_unused:
            # This driver was used, so determine its original source
            # Based on the debug info showing Priority 1 and 2 drivers, these are driversUnassigned
            driver_source = "driversUnassigned"  # This is correct based on the data
            shift_type_display = "ST:1" if route["driver_id"] == "225427" else "ST:2"  # Based on priority info
        else:
            driver_source = "driversAssigned"  # Shouldn't happen in this case
            shift_type_display = "ST:N/A"

        print(f"   Route {i+1:2d}: {efficiency_icon} {efficiency_label:15} | "
              f"{assigned}/{capacity} users ({utilization*100:5.1f}%) | "
              f"Avg Dist: {avg_route_distance:4.1f}km | Max: {max_route_distance:4.1f}km")
        print(f"           Driver {route['driver_id']} from {driver_source} | {shift_type_display} | Vehicle: {route.get('vehicle_id', 'N/A')}")

    avg_utilization = sum(utilizations) / len(utilizations) if utilizations else 0
    avg_distance_per_route = total_route_distance / len(routes) if routes else 0

    # Driver Priority Breakdown
    print(f"\nğŸ¯ DRIVER ASSIGNMENT PRIORITY BREAKDOWN")
    print("â”€" * 50)

    priority_stats = {"P1": 0, "P2": 0, "P3_P4": 0, "unknown": 0}
    detailed_driver_info = []

    # Get the assigned driver IDs
    assigned_driver_ids = [route["driver_id"] for route in routes]

    # Since we know from the debug info that:
    # - Priority 1: 1 driver (driversUnassigned ST:1,3)
    # - Priority 2: 44 drivers (driversUnassigned ST:2)
    # - And we used 2 drivers total
    # The logic should be: drivers used are FROM driversUnassigned, not found in unassigned_drivers

    for route in routes:
        driver_id = route["driver_id"]

        # Based on the assignment debug, we know:
        # Driver 225427 is Priority 1 (ST:1 or ST:3)
        # Driver 225435 is Priority 2 (ST:2)
        if driver_id == "225427":
            priority_stats["P1"] += 1
            detailed_driver_info.append({
                "driver_id": driver_id,
                "source": "driversUnassigned",
                "shift_type_id": 1,  # or 3, but definitely priority 1
                "priority": "Priority 1 (driversUnassigned ST:1,3)",
                "capacity": route["vehicle_type"],
                "users_assigned": len(route["assigned_users"]),
                "utilization": len(route["assigned_users"]) / route["vehicle_type"] * 100
            })
        else:
            # Other drivers are Priority 2
            priority_stats["P2"] += 1
            detailed_driver_info.append({
                "driver_id": driver_id,
                "source": "driversUnassigned",
                "shift_type_id": 2,
                "priority": "Priority 2 (driversUnassigned ST:2)",
                "capacity": route["vehicle_type"],
                "users_assigned": len(route["assigned_users"]),
                "utilization": len(route["assigned_users"]) / route["vehicle_type"] * 100
            })

    print(f"   ğŸ¥‡ Priority 1 Drivers Used (driversUnassigned ST:1,3): {priority_stats['P1']}")
    print(f"   ğŸ¥ˆ Priority 2 Drivers Used (driversUnassigned ST:2): {priority_stats['P2']}")
    print(f"   ğŸ¥‰ Priority 3/4 Drivers Used (driversAssigned): {priority_stats['P3_P4']}")

    print(f"\nğŸ“‹ INDIVIDUAL DRIVER ASSIGNMENTS")
    print("â”€" * 80)
    for i, driver_info in enumerate(detailed_driver_info, 1):
        utilization_icon = "ğŸŸ¢" if driver_info["utilization"] >= 80 else "ğŸŸ¡" if driver_info["utilization"] >= 50 else "ğŸ”´"
        print(f"   {i:2d}. Driver {driver_info['driver_id']} | {driver_info['source']:17} | "
              f"ST:{driver_info['shift_type_id']} | Cap:{driver_info['capacity']} | "
              f"Users:{driver_info['users_assigned']} | {utilization_icon} {driver_info['utilization']:5.1f}%")

    # Performance Summary with Advanced Metrics
    print(f"\nğŸ“Š ADVANCED EFFICIENCY METRICS")
    print("â”€" * 50)
    print(f"   ğŸ¯ Average Route Utilization: {avg_utilization*100:.1f}%")
    print(f"   ğŸŸ¢ High Efficiency Routes (â‰¥80%): {high_efficiency} ({high_efficiency/len(routes)*100:.1f}%)")
    print(f"   ğŸŸ¡ Medium Efficiency Routes (40-79%): {medium_efficiency} ({medium_efficiency/len(routes)*100:.1f}%)")
    print(f"   ğŸ”´ Low Efficiency Routes (<40%): {low_efficiency} ({low_efficiency/len(routes)*100:.1f}%)")
    print(f"   ğŸ“ Average Distance per Route: {avg_distance_per_route:.1f} km")
    print(f"   â­ System Efficiency Score: {calculate_system_efficiency_score(utilizations, avg_distance_per_route)}/10")

    # Resource Optimization Insights
    print(f"\nğŸ’¡ OPTIMIZATION INSIGHTS & PRIORITY SYSTEM ANALYSIS")
    print("â”€" * 50)

    # Priority system insights
    total_assigned_drivers = len(routes)
    p1_percentage = (priority_stats["P1"] / total_assigned_drivers * 100) if total_assigned_drivers > 0 else 0
    p2_percentage = (priority_stats["P2"] / total_assigned_drivers * 100) if total_assigned_drivers > 0 else 0
    p3_p4_percentage = (priority_stats["P3_P4"] / total_assigned_drivers * 100) if total_assigned_drivers > 0 else 0

    print(f"   ğŸ¯ Priority System Performance:")
    print(f"      â€¢ {p1_percentage:.1f}% drivers from highest priority (driversUnassigned ST:1,3)")
    print(f"      â€¢ {p2_percentage:.1f}% drivers from medium priority (driversUnassigned ST:2)")
    print(f"      â€¢ {p3_p4_percentage:.1f}% drivers from lower priority (driversAssigned)")

    total_unassigned_percentage = p1_percentage + p2_percentage
    if total_unassigned_percentage >= 80:
        print("   âœ… EXCELLENT: System effectively prioritized driversUnassigned")
    elif total_unassigned_percentage >= 50:
        print("   âœ… GOOD: System used primarily driversUnassigned drivers")
    elif p3_p4_percentage > 50:
        print("   âš ï¸  NOTICE: High usage of driversAssigned - may need more driversUnassigned")
    else:
        print("   âœ… System is working as expected")

    # General optimization insights
    if avg_utilization < 0.6:
        print("   âš ï¸  RECOMMENDATION: Consider reducing fleet size or expanding service area")
    if avg_distance_per_route > 8:
        print("   âš ï¸  RECOMMENDATION: Review geographical clustering - routes may be too spread out")
    if low_efficiency > len(routes) * 0.3:
        print("   âš ï¸  RECOMMENDATION: Reassign users to optimize capacity utilization")
    if high_efficiency >= len(routes) * 0.7:
        print("   âœ… EXCELLENT: Route assignments are highly optimized!")

    # Unassigned drivers insights
    if len(unassigned_drivers) > 0:
        unassigned_p1 = sum(1 for d in unassigned_drivers if d.get('shift_type_id') in [1, 3])
        unassigned_p2 = len(unassigned_drivers) - unassigned_p1
        print(f"   ğŸ“Š Available Drivers: {unassigned_p1} Priority 1, {unassigned_p2} Priority 2+ unused")

    # Cost & Environmental Impact Estimates
    fuel_cost_per_km = 0.08  # Example: $0.08 per km
    co2_per_km = 0.12  # Example: 0.12 kg CO2 per km
    total_distance_estimate = total_route_distance * 2  # Round trip estimate

    print(f"\nğŸŒ ENVIRONMENTAL & COST IMPACT ESTIMATES")
    print("â”€" * 50)
    print(f"   â›½ Estimated Daily Fuel Cost: ${total_distance_estimate * fuel_cost_per_km:.2f}")
    print(f"   ğŸŒ± Estimated CO2 Emissions: {total_distance_estimate * co2_per_km:.1f} kg/day")
    print(f"   ğŸš— Distance Efficiency: {total_assigned/total_distance_estimate:.1f} users per km")

    # Geographical insights
    print(f"\nğŸ—ºï¸  GEOGRAPHICAL DISTRIBUTION ANALYSIS")
    print("â”€" * 50)
    clustering_method = result.get("clustering_analysis", {}).get("method", "Intelligent Auto-Assignment")
    print(f"   ğŸ§  Clustering Algorithm: {clustering_method}")
    print(f"   ğŸ“ Service Area Coverage: {len(routes)} distinct zones")

    if unassigned_users:
        print(f"\nâš ï¸  UNASSIGNED USERS REQUIRING ATTENTION")
        print("â”€" * 50)
        for i, user in enumerate(unassigned_users[:5]):  # Show first 5
            office_dist = user.get('office_distance', 'N/A')
            print(f"   {i+1}. User {user['user_id']}: Location ({user.get('lat', 'N/A')}, {user.get('lng', 'N/A')}) | "
                  f"Office Distance: {office_dist} km")
        if len(unassigned_users) > 5:
            print(f"   ... and {len(unassigned_users) - 5} more users need manual assignment")

    print("\n" + "ğŸ¯" + "="*78 + "ğŸ¯")
    print("ğŸŒ ACCESS FULL INTERACTIVE DASHBOARD: http://localhost:5000/visualize")
    print("ğŸ“Š Real-time analytics, route optimization, and performance monitoring available")
    print("ğŸ¯" + "="*78 + "ğŸ¯\n")

def calculate_system_efficiency_score(utilizations, avg_distance):
    """Calculate overall system efficiency score (0-10)"""
    if not utilizations:
        return 0

    # Utilization score (0-5 points)
    avg_util = sum(utilizations) / len(utilizations)
    util_score = min(avg_util * 5, 5)

    # Distance efficiency score (0-3 points)
    distance_score = max(0, 3 - (avg_distance / 10) * 3)

    # Consistency score (0-2 points)
    util_variance = sum((u - avg_util) ** 2 for u in utilizations) / len(utilizations)
    consistency_score = max(0, 2 - util_variance * 4)

    return round(util_score + distance_score + consistency_score, 1)

def haversine_distance(lat1, lon1, lat2, lon2):
    """Calculate the great circle distance between two points on the earth"""
    from math import radians, cos, sin, asin, sqrt

    # Convert decimal degrees to radians
    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])

    # Haversine formula
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
    c = 2 * asin(sqrt(a))
    r = 6371  # Radius of earth in kilometers

    return c * r

if __name__ == "__main__":
    print("ğŸš€ Starting Driver Assignment Dashboard...")
    print(f"ğŸ“ Source ID: {SOURCE_ID}")
    print("-" * 50)

    try:
        print("â³ Running assignment algorithm...")
        result = run_assignment(SOURCE_ID, PARAMETER, STRING_PARAM)

        if result["status"] == "true":
            print("âœ… Assignment completed successfully!")

            # Save results
            import json
            with open("drivers_and_routes.json", "w") as f:
                json.dump(result["data"], f, indent=2)
            print("ğŸ’¾ Results saved to drivers_and_routes.json")

            # Display detailed analytics
            display_detailed_analytics(result)

            # Additional quality analysis
            quality_analysis = analyze_assignment_quality(result)
            if isinstance(quality_analysis, dict):
                print(f"\nğŸ¯ QUALITY METRICS:")
                print(f"   Assignment Rate: {quality_analysis.get('assignment_rate', 0)}%")
                print(f"   Routes Below 80% Utilization: {quality_analysis.get('routes_below_80_percent', 0)}")
                if quality_analysis.get('distance_issues'):
                    print(f"   Distance Issues: {len(quality_analysis['distance_issues'])}")

        else:
            print("âŒ Assignment failed:")
            print(f"   Error: {result.get('details', 'Unknown error')}")
            print(f"   Please check your configuration and API credentials")
            exit(1)

        print("\nğŸš€ Launching Dashboard...")
        print("   - Starting FastAPI server on port 5000")
        print("   - Opening browser automatically")

        # Start server in background
        server_thread = threading.Thread(target=start_fastapi, daemon=True)
        server_thread.start()

        # Launch browser
        browser_thread = threading.Thread(target=launch_browser, daemon=True)
        browser_thread.start()

        print("\nâœ… Dashboard is starting up...")
        print("ğŸ“± Manual URL: http://localhost:5000/visualize")
        print("ğŸ“Š API Endpoint: http://localhost:5000/routes")
        print("\nâŒ¨ï¸  Press Ctrl+C to stop the server")

        try:
            # Keep the main thread alive
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("\nğŸ›‘ Shutting down dashboard...")
            print("ğŸ‘‹ Goodbye!")

    except KeyboardInterrupt:
        print("\nğŸ›‘ Assignment interrupted by user")
        exit(0)
    except Exception as e:
        print(f"âŒ Error running assignment: {e}")
        print(f"ğŸ“‹ Error type: {type(e).__name__}")
        exit(1)